{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1462296,"sourceType":"datasetVersion","datasetId":857191}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q ultralytics\n!pip uninstall -y wandb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-16T03:17:31.011050Z","iopub.execute_input":"2024-04-16T03:17:31.011418Z","iopub.status.idle":"2024-04-16T03:17:51.805327Z","shell.execute_reply.started":"2024-04-16T03:17:31.011388Z","shell.execute_reply":"2024-04-16T03:17:51.804060Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Found existing installation: wandb 0.16.5\nUninstalling wandb-0.16.5:\n  Successfully uninstalled wandb-0.16.5\n","output_type":"stream"}]},{"cell_type":"code","source":"import cv2\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom IPython.display import Image\nfrom ultralytics import YOLO\nfrom collections import defaultdict\nfrom scipy.optimize import linear_sum_assignment","metadata":{"execution":{"iopub.status.busy":"2024-04-16T03:18:55.263782Z","iopub.execute_input":"2024-04-16T03:18:55.264802Z","iopub.status.idle":"2024-04-16T03:18:55.272371Z","shell.execute_reply.started":"2024-04-16T03:18:55.264756Z","shell.execute_reply":"2024-04-16T03:18:55.271447Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import os\n# Path to the training images directory\ntrain_images_dir = '/kaggle/input/coco-2017-dataset/coco2017/train2017'\ntest_images_dir = '/kaggle/input/coco-2017-dataset/coco2017/test2017'\nval_images_dir = '/kaggle/input/coco-2017-dataset/coco2017/val2017'\n\ntrain_images_count = len(os.listdir(train_images_dir))\ntest_images_count = len(os.listdir(test_images_dir))\nval_images_count = len(os.listdir(val_images_dir))\nprint(f\"Number of images in the training set: {train_images_count}, test set: {test_images_count}, validation set: {val_images_count}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-16T03:18:55.657379Z","iopub.execute_input":"2024-04-16T03:18:55.657997Z","iopub.status.idle":"2024-04-16T03:18:55.739004Z","shell.execute_reply.started":"2024-04-16T03:18:55.657968Z","shell.execute_reply":"2024-04-16T03:18:55.738136Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Number of images in the training set: 118287, test set: 40670, validation set: 5000\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\nimport os\nfrom shutil import copy2\nfrom tqdm import tqdm\nfrom concurrent.futures import ProcessPoolExecutor\n\n# Define the COCO dataset directory and the new directory for person class data\ncoco_dir = '/kaggle/input/coco-2017-dataset/coco2017'\nyolov8_dir = '/kaggle/working/yolov8'\n\n# Create the necessary directories\nphases = ['train','val']  \nfor phase in phases:\n    os.makedirs(os.path.join(yolov8_dir, phase, 'images'), exist_ok=True)\n    os.makedirs(os.path.join(yolov8_dir, phase, 'labels'), exist_ok=True)\n\n# Function to convert COCO bounding box to normalized YOLO format\ndef convert_to_yolo(box, img_width, img_height):\n    x_center = (box[0] + box[2] / 2) / img_width\n    y_center = (box[1] + box[3] / 2) / img_height\n    width = box[2] / img_width\n    height = box[3] / img_height\n    return x_center, y_center, width, height\n\n# Function to process each image and its annotations\ndef process_image(data):\n    img, person_annotations, phase = data\n    img_id = img['id']\n    img_width, img_height = img['width'], img['height']\n    file_name = img['file_name']\n    output_dir = os.path.join(yolov8_dir, phase)  # Adjusted to use phase-specific folders\n\n    # Prepare label data\n    label_data = []\n    for ann in person_annotations:\n        if ann['image_id'] == img_id:\n            bbox = convert_to_yolo(ann['bbox'], img_width, img_height)\n            label_data.append(f\"0 {bbox[0]} {bbox[1]} {bbox[2]} {bbox[3]}\")\n\n    # Write label file\n    label_file_path = os.path.join(output_dir, 'labels', f'{os.path.splitext(file_name)[0]}.txt')\n    with open(label_file_path, 'w') as label_file:\n        label_file.write('\\n'.join(label_data))\n\n    # Copy the image\n    src_path = os.path.join(coco_dir, f'{phase}2017', file_name)\n    dst_path = os.path.join(output_dir, 'images', file_name)\n    copy2(src_path, dst_path)\n\nfor phase in phases:\n\n    annotations_file = f'instances_{phase}2017.json'\n    annotations_path = os.path.join(coco_dir, 'annotations', annotations_file)\n\n    with open(annotations_path) as f:\n        annotations_data = json.load(f)\n\n    print(f\"Processing {phase} annotations...\")\n    person_category_id = next(cat['id'] for cat in annotations_data['categories'] if cat['name'] == \"person\")\n\n    # Create a mapping from image_id to annotations\n    annotations_by_image_id = {}\n    for annotation in annotations_data['annotations']:\n        if annotation['category_id'] == person_category_id:\n            if annotation['image_id'] not in annotations_by_image_id:\n                annotations_by_image_id[annotation['image_id']] = []\n            annotations_by_image_id[annotation['image_id']].append(annotation)\n\n    # Now use the mapping to create img_data_list efficiently\n    img_data_list = [(img, annotations_by_image_id.get(img['id'], []), phase) \n                     for img in annotations_data['images'] \n                     if img['id'] in annotations_by_image_id]\n\n    with ProcessPoolExecutor(max_workers=os.cpu_count()) as executor:\n        list(tqdm(executor.map(process_image, img_data_list), total=len(img_data_list), desc=f'Processing {phase} images'))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-16T03:18:56.218271Z","iopub.execute_input":"2024-04-16T03:18:56.219159Z","iopub.status.idle":"2024-04-16T03:23:26.449800Z","shell.execute_reply.started":"2024-04-16T03:18:56.219097Z","shell.execute_reply":"2024-04-16T03:23:26.448629Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Processing train annotations...\n","output_type":"stream"},{"name":"stderr","text":"Processing train images: 100%|██████████| 64115/64115 [03:44<00:00, 285.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Processing val annotations...\n","output_type":"stream"},{"name":"stderr","text":"Processing val images: 100%|██████████| 2693/2693 [00:08<00:00, 306.62it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport random\n\n# Define source and destination directories\nsrc_images_dir = '/kaggle/working/yolov8/train/images'\nsrc_labels_dir = '/kaggle/working/yolov8/train/labels'\ndest_images_dir = '/kaggle/working/yolov8/test/images'\ndest_labels_dir = '/kaggle/working/yolov8/test/labels'\n\n# Ensure destination directories exist\nos.makedirs(dest_images_dir, exist_ok=True)\nos.makedirs(dest_labels_dir, exist_ok=True)\n\n# List all image files in the source directory\nimage_files = [f for f in os.listdir(src_images_dir) if os.path.isfile(os.path.join(src_images_dir, f))]\n\n# Randomly select 10% of these image files\nselected_images = random.sample(image_files, max(1, len(image_files) // 10))  # Ensure at least one file is selected if not empty\n\n# Move selected image files and their corresponding label files to the destination directories\nfor image_file in tqdm(selected_images):\n    # Move image\n    src_image_path = os.path.join(src_images_dir, image_file)\n    dest_image_path = os.path.join(dest_images_dir, image_file)\n    os.rename(src_image_path, dest_image_path)\n    \n    label_file = os.path.splitext(image_file)[0] + '.txt'  # Assuming label files are .txt with same base filename\n    src_label_path = os.path.join(src_labels_dir, label_file)\n    dest_label_path = os.path.join(dest_labels_dir, label_file)\n    if os.path.exists(src_label_path):  \n        os.rename(src_label_path, dest_label_path)\n\nprint(f\"Moved {len(selected_images)} images and their corresponding labels to test directories.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-16T03:23:26.452502Z","iopub.execute_input":"2024-04-16T03:23:26.453312Z","iopub.status.idle":"2024-04-16T03:23:27.416383Z","shell.execute_reply.started":"2024-04-16T03:23:26.453279Z","shell.execute_reply":"2024-04-16T03:23:27.415499Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"100%|██████████| 6411/6411 [00:00<00:00, 13848.98it/s]","output_type":"stream"},{"name":"stdout","text":"Moved 6411 images and their corresponding labels to test directories.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"config = \"\"\"\npath: /kaggle/working/yolov8  \ntrain: train                \nval: test                      \n\nnames:\n  0: person\n \n\"\"\"\nwith open(\"/kaggle/working/coco.yaml\", 'w') as f:\n    f.write(config)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T03:23:27.417646Z","iopub.execute_input":"2024-04-16T03:23:27.417997Z","iopub.status.idle":"2024-04-16T03:23:27.423980Z","shell.execute_reply.started":"2024-04-16T03:23:27.417963Z","shell.execute_reply":"2024-04-16T03:23:27.423139Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from ultralytics import YOLO\nmodel = YOLO('yolov8s.pt')\ndata_yaml = '/kaggle/working/coco.yaml' \nresults = model.train(data=data_yaml, epochs=2, imgsz=640,batch=128, classes=[0],device=[0,1])","metadata":{"execution":{"iopub.status.busy":"2024-04-16T03:23:27.425922Z","iopub.execute_input":"2024-04-16T03:23:27.426196Z","iopub.status.idle":"2024-04-16T03:52:58.943438Z","shell.execute_reply.started":"2024-04-16T03:23:27.426173Z","shell.execute_reply":"2024-04-16T03:52:58.942235Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8s.pt to 'yolov8s.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 21.5M/21.5M [00:00<00:00, 165MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Ultralytics YOLOv8.1.47 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\n                                                      CUDA:1 (Tesla T4, 15102MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/kaggle/working/coco.yaml, epochs=2, time=None, patience=100, batch=128, imgsz=640, save=True, save_period=-1, cache=False, device=[0, 1], workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=[0], retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 755k/755k [00:00<00:00, 13.3MB/s]\n2024-04-16 03:23:31,810\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n2024-04-16 03:23:34,436\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n2024-04-16 03:23:39.431320: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-16 03:23:39.431423: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-16 03:23:39.656259: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Overriding model.yaml nc=80 with nc=1\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \nModel summary: 225 layers, 11135987 parameters, 11135971 gradients, 28.6 GFLOPs\n\nTransferred 349/355 items from pretrained weights\n\u001b[34m\u001b[1mDDP:\u001b[0m debug command /opt/conda/bin/python3.10 -m torch.distributed.run --nproc_per_node 2 --master_port 47609 /root/.config/Ultralytics/DDP/_temp_75gix0xh132729165414160.py\nUltralytics YOLOv8.1.47 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\n                                                      CUDA:1 (Tesla T4, 15102MiB)\n","output_type":"stream"},{"name":"stderr","text":"2024-04-16 03:24:01.971839: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-16 03:24:01.971900: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-16 03:24:01.973555: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\nOverriding model.yaml nc=80 with nc=1\nTransferred 349/355 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\nDownloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6.23M/6.23M [00:00<00:00, 67.8MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/yolov8/train/labels... 57704 images, 0 backgrounds, 0 corrupt: 100%|██████████| 57704/57704 [00:58<00:00, 987.07it/s] \n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/yolov8/train/labels.cache\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/yolov8/test/labels... 6411 images, 0 backgrounds, 0 corrupt: 100%|██████████| 6411/6411 [00:07<00:00, 866.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/yolov8/test/labels.cache\nPlotting labels to runs/detect/train/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.001), 63 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/detect/train\u001b[0m\nStarting training for 2 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        1/2      15.2G      1.037     0.9577      1.131        467        640: 100%|██████████| 451/451 [12:01<00:00,  1.60s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:53<00:00,  1.04s/it]\n","output_type":"stream"},{"name":"stdout","text":"                   all       6411      26473      0.774      0.656      0.742      0.496\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        2/2      14.5G      1.063     0.8647      1.146        358        640: 100%|██████████| 451/451 [12:14<00:00,  1.63s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:54<00:00,  1.08s/it]\n","output_type":"stream"},{"name":"stdout","text":"                   all       6411      26473      0.786      0.669      0.757      0.519\n\n2 epochs completed in 0.437 hours.\nOptimizer stripped from runs/detect/train/weights/last.pt, 22.5MB\nOptimizer stripped from runs/detect/train/weights/best.pt, 22.5MB\n\nValidating runs/detect/train/weights/best.pt...\nUltralytics YOLOv8.1.47 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\n                                                      CUDA:1 (Tesla T4, 15102MiB)\nModel summary (fused): 168 layers, 11125971 parameters, 0 gradients, 28.4 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 51/51 [00:54<00:00,  1.07s/it]\n","output_type":"stream"},{"name":"stdout","text":"                   all       6411      26473      0.786      0.669      0.756      0.519\nSpeed: 0.1ms preprocess, 3.3ms inference, 0.0ms loss, 0.9ms postprocess per image\nResults saved to \u001b[1mruns/detect/train\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# function to calculate Intersection over Union (IoU) for two bounding boxes\ndef calc_iou(box1, box2): # box1 and box2 are (x, y, w, h)\n    # Calculate the coordinates of the corners of the two boxes\n    x1_min = box1[0] - box1[2] / 2 # x - w/2\n    x1_max = box1[0] + box1[2] / 2 # x + w/2\n    y1_min = box1[1] - box1[3] / 2 # y - h/2\n    y1_max = box1[1] + box1[3] / 2 # y + h/2\n\n    x2_min = box2[0] - box2[2] / 2 # x - w/2\n    x2_max = box2[0] + box2[2] / 2 # x + w/2\n    y2_min = box2[1] - box2[3] / 2 # y - h/2\n    y2_max = box2[1] + box2[3] / 2 # y + h/2\n\n    # Calculate the coordinates for the intersection rectangle\n    inter_x_min = max(x1_min, x2_min) # max of the two x mins\n    inter_y_min = max(y1_min, y2_min) # max of the two y mins\n    inter_x_max = min(x1_max, x2_max) # min of the two x maxes\n    inter_y_max = min(y1_max, y2_max) # min of the two y maxes \n\n    # If there is no intersection, return 0\n    if inter_x_max < inter_x_min or inter_y_max < inter_y_min:\n        return 0.0\n\n    # Calculate intersection area\n    inter_area = (inter_x_max - inter_x_min) * (inter_y_max - inter_y_min)\n\n    # Calculate area of both bounding boxes\n    area1 = (x1_max - x1_min) * (y1_max - y1_min)\n    area2 = (x2_max - x2_min) * (y2_max - y2_min)\n\n    # Compute the Intersection over Union by taking the intersection area and dividing it by the sum of prediction + ground-truth areas - the interesection area\n    iou = inter_area / float(area1 + area2 - inter_area)\n\n    # Ensure IOU is within correct bounds\n    assert 0.0 <= iou <= 1.0, \"IOU must be between 0 and 1\"\n    return iou","metadata":{"execution":{"iopub.status.busy":"2024-04-16T03:52:58.945059Z","iopub.execute_input":"2024-04-16T03:52:58.945725Z","iopub.status.idle":"2024-04-16T03:52:58.956997Z","shell.execute_reply.started":"2024-04-16T03:52:58.945695Z","shell.execute_reply":"2024-04-16T03:52:58.955982Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom collections import defaultdict\nfrom scipy.optimize import linear_sum_assignment\n\nyolov8_dir = \"/kaggle/working/yolov8/\"\ntest_images_folder = yolov8_dir + \"test/images/\"\ntest_labels_folder = yolov8_dir + \"test/labels/\"\ntest_files = os.listdir(test_images_folder)\n\nsum_iou = 0\nious = defaultdict(float) # Store the IOU for each test image\nnum_tested = 0  # Count of images actually tested (i.e., having both gt and preds)\n\nground_truths = {} # Store the ground truths for each test image \nfor test_file in test_files:\n    label_file = test_labels_folder + os.path.splitext(test_file)[0] + '.txt' # Get the label file for the test image\n    with open(label_file, 'r') as file:\n        lines = file.readlines() # Read the lines of the label file\n        ground_truths[test_file] = [list(map(float, line.strip().split())) for line in lines] # Store the ground truths\n\n# Iterate through the test files to test the performance\nfor test_file in tqdm(test_files):\n    res = model.predict(test_images_folder + test_file, classes=[0], verbose=False) # Get the predictions for the test image\n    \n    gt = np.array(ground_truths[test_file]) # Get the ground truths for the test image\n    preds = res[0].boxes.xywhn.cpu().numpy() # Get the predictions for the test image\n    \n    if len(gt) == 0 or len(preds) == 0: # Skip the mean IOU calculation for this file if there are no gt or predictions\n        continue  \n\n    num_tested += 1  # Increment only if there are both gt and predictions\n\n    iou_matrix = np.zeros((len(gt), len(preds))) # Initialize the IOU matrix\n    for i in range(len(gt)): # Calculate the IOU for each pair of gt and prediction\n        for j in range(len(preds)): \n            iou_matrix[i, j] = calc_iou(gt[i], preds[j])\n\n    # Do the Hungarian matching algorithm\n    gt_idx, pred_idx = linear_sum_assignment(1 - iou_matrix)\n    assigned_ious = iou_matrix[gt_idx, pred_idx]\n    \n    # Compute mean across all instances in the image\n    mean_iou = np.mean(assigned_ious) \n\n    assert mean_iou <= 1.0, \"Mean IOU should not exceed 1.0\"\n    \n    sum_iou += mean_iou\n    ious[test_file] = (mean_iou, assigned_ious)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T03:54:04.543781Z","iopub.execute_input":"2024-04-16T03:54:04.544203Z","iopub.status.idle":"2024-04-16T03:56:03.844135Z","shell.execute_reply.started":"2024-04-16T03:54:04.544174Z","shell.execute_reply":"2024-04-16T03:56:03.843153Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"100%|██████████| 6411/6411 [01:56<00:00, 54.84it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"average_iou = sum_iou / num_tested if num_tested > 0 else 0\nprint(f\"Average IOU: {average_iou}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-16T03:57:41.788606Z","iopub.execute_input":"2024-04-16T03:57:41.788989Z","iopub.status.idle":"2024-04-16T03:57:41.794745Z","shell.execute_reply.started":"2024-04-16T03:57:41.788958Z","shell.execute_reply":"2024-04-16T03:57:41.793661Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Average IOU: 0.7522543195211435\n","output_type":"stream"}]}]}